{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7VXYScXM5B4","executionInfo":{"status":"ok","timestamp":1670353156827,"user_tz":-210,"elapsed":29160,"user":{"displayName":"temp tempy","userId":"06017972767897729165"}},"outputId":"79504ee3-d3c5-4c8a-bda8-484d66eafa01"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"elKutKZBI_Bq","executionInfo":{"status":"ok","timestamp":1670353158450,"user_tz":-210,"elapsed":5,"user":{"displayName":"temp tempy","userId":"06017972767897729165"}},"outputId":"df093cbc-ac5d-4e54-a214-fc684f4e0e3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1pBBBcAQFBahPZn8EeVxX0HyFNnQB0OZk/NLU/HW2\n"]}],"source":["# %cd /content/drive/MyDrive/Education/NLU/HW2\n","%cd /content/drive/MyDrive/NLU/HW2"]},{"cell_type":"markdown","source":["#### install packages"],"metadata":{"id":"8srA7bE4JZke"}},{"cell_type":"code","source":["!pip install -U transformers\n","!pip install simplet5\n","\n","!wget https://www.comp.nus.edu.sg/%7Ekanmy/courses/practicalNLP_2008/packages/conlleval.pl  "],"metadata":{"id":"GTL3lBr6JYZO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bert"],"metadata":{"id":"JDFQB6HbJgVu"}},{"cell_type":"markdown","source":["### Create data for bert model"],"metadata":{"id":"yihdeE3TJduV"}},{"cell_type":"code","source":["!python bert/preprocess.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1yIxNvKcJdOO","executionInfo":{"status":"ok","timestamp":1670253739398,"user_tz":-210,"elapsed":39902,"user":{"displayName":"temp3 tempy","userId":"06251379254060818571"}},"outputId":"fca76d96-a682-41bf-99de-1051f17ad63a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["load bert tokenizer..\n","reading train and val data..\n","reading test data..\n","create train and val tensor data..\n","create test tensor data..\n","data shape after remove redundant texts:\n","\t train data: torch.Size([23016, 30])\n","\t val data: torch.Size([3789, 30])\n","\t test data: torch.Size([7427, 30])\n","create dataloader for train and val..\n","create dataloader for test..\n","save prepared data..\n","data is saved in bert/data/\n"]}]},{"cell_type":"markdown","source":["### Train model"],"metadata":{"id":"kfAMXmtXLkf_"}},{"cell_type":"code","source":["!python bert/train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N41bt6OdLkot","executionInfo":{"status":"ok","timestamp":1670155170106,"user_tz":-210,"elapsed":1441952,"user":{"displayName":"Majid A","userId":"00481875298271315487"}},"outputId":"7cb87910-f20a-4a3b-c8a8-9262deb92414"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["load train and val dataloader..\n","device: cuda\n","create model..\n","#########################\n","Epoch 0 (train): 100% 720/720 [02:14<00:00,  5.35it/s, loss=0.654]\n","validation: 100% 119/119 [00:06<00:00, 17.80it/s, loss=0.331]\n","Epoch 1 (train): 100% 720/720 [02:15<00:00,  5.32it/s, loss=0.272]\n","validation: 100% 119/119 [00:06<00:00, 17.61it/s, loss=0.217]\n","Epoch 2 (train): 100% 720/720 [02:15<00:00,  5.31it/s, loss=0.201]\n","validation: 100% 119/119 [00:06<00:00, 17.62it/s, loss=0.217]\n","Epoch 3 (train): 100% 720/720 [02:15<00:00,  5.32it/s, loss=0.169]\n","validation: 100% 119/119 [00:06<00:00, 17.60it/s, loss=0.202]\n","Epoch 4 (train): 100% 720/720 [02:15<00:00,  5.31it/s, loss=0.153]\n","validation: 100% 119/119 [00:06<00:00, 17.46it/s, loss=0.202]\n","Epoch 5 (train): 100% 720/720 [02:15<00:00,  5.31it/s, loss=0.136]\n","validation: 100% 119/119 [00:06<00:00, 17.62it/s, loss=0.172]\n","Epoch 6 (train): 100% 720/720 [02:15<00:00,  5.31it/s, loss=0.137]\n","validation: 100% 119/119 [00:06<00:00, 17.60it/s, loss=0.172]\n","Epoch 7 (train): 100% 720/720 [02:15<00:00,  5.31it/s, loss=0.12]\n","validation: 100% 119/119 [00:06<00:00, 17.56it/s, loss=0.185]\n","Epoch 8 (train): 100% 720/720 [02:15<00:00,  5.31it/s, loss=0.101]\n","validation: 100% 119/119 [00:06<00:00, 17.55it/s, loss=0.187]\n","Epoch 9 (train): 100% 720/720 [02:15<00:00,  5.31it/s, loss=0.0987]\n","validation: 100% 119/119 [00:06<00:00, 17.56it/s, loss=0.19]\n","#########################\n","The loss change diagram was saved in bert/model/loss.jpg\n"]}]},{"cell_type":"markdown","source":["### Validate model"],"metadata":{"id":"p3ZTd2ifX86H"}},{"cell_type":"code","source":["!python bert/evaluate.py"],"metadata":{"id":"lRsjTyR_X9Bj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670155845225,"user_tz":-210,"elapsed":29308,"user":{"displayName":"Majid A","userId":"00481875298271315487"}},"outputId":"9430c5b6-c1a8-4d79-d084-fba0b49d81d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["load test data..\n","device: cuda\n","using cuda\n","testing: 100% 233/233 [00:17<00:00, 13.20it/s, loss=0.202]\n","result data is saved in 'bert/result/bert_result.txt'\n","\n","evaluation scores:\n","slot scores: [precision:91.06, recall:91.5, F1:91.28]\n","intent accuracy: 0.988\n"]}]},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"up_MlK_ooxgh"}},{"cell_type":"markdown","source":["### Joint slat fillin and intent detection"],"metadata":{"id":"f-vVBDx0vpMn"}},{"cell_type":"markdown","source":["#### Create data for bert model"],"metadata":{"id":"K58UOgn_ozNX"}},{"cell_type":"code","source":["!python T5/preprocess.py --intent_detection True --slot_filling True"],"metadata":{"id":"HRQtOGXZo5hS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670356815473,"user_tz":-210,"elapsed":2494,"user":{"displayName":"temp tempy","userId":"06017972767897729165"}},"outputId":"6331417f-c41a-4e93-cf58-8b71dcdf10d9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["reading train and val data..\n","reading test data..\n","number of data after remove redundant texts:\n","\t train data: 23016\n","\t val data: 3789\n","\t test data: 7427\n","save prepared data..\n","data is saved in T5/data/\n"]}]},{"cell_type":"markdown","source":["#### Train model"],"metadata":{"id":"nNoHxvpuurVB"}},{"cell_type":"code","source":["!python T5/train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYhDZQ0mqxG_","outputId":"63ba8327-fb8e-4366-a990-462d256ea348","executionInfo":{"status":"ok","timestamp":1670356576007,"user_tz":-210,"elapsed":3339147,"user":{"displayName":"temp tempy","userId":"06017972767897729165"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Global seed set to 42\n","load train and val data..\n","Downloading: 100% 773k/773k [00:00<00:00, 29.3MB/s]\n","Downloading: 100% 1.32M/1.32M [00:00<00:00, 30.5MB/s]\n","Downloading: 100% 1.17k/1.17k [00:00<00:00, 1.78MB/s]\n","Downloading: 100% 850M/850M [00:11<00:00, 75.1MB/s]\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type                       | Params\n","-----------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 222 M \n","-----------------------------------------------------\n","222 M     Trainable params\n","0         Non-trainable params\n","222 M     Total params\n","891.614   Total estimated model params size (MB)\n","Global seed set to 42\n","Epoch 0:  86% 720/839 [08:20<01:22,  1.44it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  87% 730/839 [08:21<01:14,  1.46it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:   8% 10/119 [00:02<00:24,  4.46it/s]\u001b[A\n","Epoch 0:  88% 740/839 [08:23<01:07,  1.47it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  17% 20/119 [00:04<00:22,  4.46it/s]\u001b[A\n","Epoch 0:  89% 750/839 [08:26<01:00,  1.48it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  25% 30/119 [00:06<00:19,  4.47it/s]\u001b[A\n","Epoch 0:  91% 760/839 [08:28<00:52,  1.50it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  34% 40/119 [00:08<00:17,  4.48it/s]\u001b[A\n","Epoch 0:  92% 770/839 [08:30<00:45,  1.51it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  42% 50/119 [00:11<00:15,  4.48it/s]\u001b[A\n","Epoch 0:  93% 780/839 [08:32<00:38,  1.52it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  50% 60/119 [00:13<00:13,  4.48it/s]\u001b[A\n","Epoch 0:  94% 790/839 [08:35<00:31,  1.53it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  59% 70/119 [00:15<00:10,  4.48it/s]\u001b[A\n","Epoch 0:  95% 800/839 [08:37<00:25,  1.55it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  67% 80/119 [00:17<00:08,  4.48it/s]\u001b[A\n","Epoch 0:  97% 810/839 [08:39<00:18,  1.56it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  76% 90/119 [00:20<00:06,  4.48it/s]\u001b[A\n","Epoch 0:  98% 820/839 [08:41<00:12,  1.57it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  84% 100/119 [00:22<00:04,  4.48it/s]\u001b[A\n","Epoch 0:  99% 830/839 [08:43<00:05,  1.58it/s, loss=0.0937, v_num=0, train_loss_step=0.0604]\n","Validating:  92% 110/119 [00:24<00:02,  4.48it/s]\u001b[A\n","Validating:  97% 115/119 [00:25<00:00,  4.49it/s]\u001b[A\n","Epoch 0: 100% 839/839 [08:47<00:00,  1.59it/s, loss=0.0937, v_num=0, train_loss_step=0.0604, val_loss_step=0.240, val_loss_epoch=0.0599]\n","Epoch 0: 100% 839/839 [08:47<00:00,  1.59it/s, loss=0.0937, v_num=0, train_loss_step=0.0604, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]tcmalloc: large alloc 1150812160 bytes == 0x125190000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 1438515200 bytes == 0xbfa56000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 1798144000 bytes == 0x125190000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 2247680000 bytes == 0x7f09d6072000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 2809602048 bytes == 0x125190000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 0: 100% 839/839 [08:56<00:00,  1.56it/s, loss=0.0937, v_num=0, train_loss_step=0.0604, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]tcmalloc: large alloc 3512008704 bytes == 0x7f0904b22000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 1:  86% 720/839 [08:17<01:22,  1.45it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:  87% 730/839 [08:19<01:14,  1.46it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:   8% 10/119 [00:02<00:24,  4.37it/s]\u001b[A\n","Epoch 1:  88% 740/839 [08:21<01:07,  1.48it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  17% 20/119 [00:04<00:22,  4.43it/s]\u001b[A\n","Epoch 1:  89% 750/839 [08:23<00:59,  1.49it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  25% 30/119 [00:06<00:19,  4.46it/s]\u001b[A\n","Epoch 1:  91% 760/839 [08:25<00:52,  1.50it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  34% 40/119 [00:09<00:17,  4.47it/s]\u001b[A\n","Epoch 1:  92% 770/839 [08:28<00:45,  1.52it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  42% 50/119 [00:11<00:15,  4.48it/s]\u001b[A\n","Epoch 1:  93% 780/839 [08:30<00:38,  1.53it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  50% 60/119 [00:13<00:13,  4.47it/s]\u001b[A\n","Epoch 1:  94% 790/839 [08:32<00:31,  1.54it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  59% 70/119 [00:15<00:10,  4.48it/s]\u001b[A\n","Epoch 1:  95% 800/839 [08:34<00:25,  1.55it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  67% 80/119 [00:17<00:08,  4.48it/s]\u001b[A\n","Epoch 1:  97% 810/839 [08:36<00:18,  1.57it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  76% 90/119 [00:20<00:06,  4.48it/s]\u001b[A\n","Epoch 1:  98% 820/839 [08:39<00:12,  1.58it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  84% 100/119 [00:22<00:04,  4.48it/s]\u001b[A\n","Epoch 1:  99% 830/839 [08:41<00:05,  1.59it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.240, val_loss_epoch=0.0599, train_loss_epoch=0.248]\n","Validating:  92% 110/119 [00:24<00:02,  4.49it/s]\u001b[A\n","Validating:  97% 115/119 [00:25<00:00,  4.49it/s]\u001b[A\n","Epoch 1: 100% 839/839 [08:44<00:00,  1.60it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.248]\n","Epoch 1: 100% 839/839 [08:44<00:00,  1.60it/s, loss=0.0549, v_num=0, train_loss_step=0.0613, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]tcmalloc: large alloc 2247680000 bytes == 0x7f0904b22000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 2809602048 bytes == 0x125190000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 3512008704 bytes == 0x7f0904b22000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 2:  86% 720/839 [08:17<01:22,  1.45it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:  87% 730/839 [08:19<01:14,  1.46it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:   8% 10/119 [00:02<00:24,  4.36it/s]\u001b[A\n","Epoch 2:  88% 740/839 [08:21<01:07,  1.48it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  17% 20/119 [00:04<00:22,  4.44it/s]\u001b[A\n","Epoch 2:  89% 750/839 [08:23<00:59,  1.49it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  25% 30/119 [00:06<00:19,  4.47it/s]\u001b[A\n","Epoch 2:  91% 760/839 [08:25<00:52,  1.50it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  34% 40/119 [00:08<00:17,  4.47it/s]\u001b[A\n","Epoch 2:  92% 770/839 [08:27<00:45,  1.52it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  42% 50/119 [00:11<00:15,  4.48it/s]\u001b[A\n","Epoch 2:  93% 780/839 [08:30<00:38,  1.53it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  50% 60/119 [00:13<00:13,  4.47it/s]\u001b[A\n","Epoch 2:  94% 790/839 [08:32<00:31,  1.54it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  59% 70/119 [00:15<00:10,  4.48it/s]\u001b[A\n","Epoch 2:  95% 800/839 [08:34<00:25,  1.55it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  67% 80/119 [00:17<00:08,  4.48it/s]\u001b[A\n","Epoch 2:  97% 810/839 [08:36<00:18,  1.57it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  76% 90/119 [00:20<00:06,  4.49it/s]\u001b[A\n","Epoch 2:  98% 820/839 [08:39<00:12,  1.58it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  84% 100/119 [00:22<00:04,  4.47it/s]\u001b[A\n","Epoch 2:  99% 830/839 [08:41<00:05,  1.59it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.190, val_loss_epoch=0.0346, train_loss_epoch=0.0681]\n","Validating:  92% 110/119 [00:24<00:02,  4.48it/s]\u001b[A\n","Validating:  97% 115/119 [00:25<00:00,  4.48it/s]\u001b[A\n","Epoch 2: 100% 839/839 [08:44<00:00,  1.60it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0681]\n","Epoch 2: 100% 839/839 [08:44<00:00,  1.60it/s, loss=0.0366, v_num=0, train_loss_step=0.0704, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]tcmalloc: large alloc 3512008704 bytes == 0x7f0904b22000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 3:  86% 720/839 [08:19<01:22,  1.44it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412] \n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:  87% 730/839 [08:20<01:14,  1.46it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:   8% 10/119 [00:02<00:25,  4.33it/s]\u001b[A\n","Epoch 3:  88% 740/839 [08:22<01:07,  1.47it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  17% 20/119 [00:04<00:22,  4.43it/s]\u001b[A\n","Epoch 3:  89% 750/839 [08:24<00:59,  1.49it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  25% 30/119 [00:06<00:19,  4.46it/s]\u001b[A\n","Epoch 3:  91% 760/839 [08:27<00:52,  1.50it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  34% 40/119 [00:09<00:17,  4.47it/s]\u001b[A\n","Epoch 3:  92% 770/839 [08:29<00:45,  1.51it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  42% 50/119 [00:11<00:15,  4.48it/s]\u001b[A\n","Epoch 3:  93% 780/839 [08:31<00:38,  1.53it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  50% 60/119 [00:13<00:13,  4.48it/s]\u001b[A\n","Epoch 3:  94% 790/839 [08:33<00:31,  1.54it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  59% 70/119 [00:15<00:10,  4.48it/s]\u001b[A\n","Epoch 3:  95% 800/839 [08:35<00:25,  1.55it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  67% 80/119 [00:17<00:08,  4.48it/s]\u001b[A\n","Epoch 3:  97% 810/839 [08:38<00:18,  1.56it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  76% 90/119 [00:20<00:06,  4.49it/s]\u001b[A\n","Epoch 3:  98% 820/839 [08:40<00:12,  1.58it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  84% 100/119 [00:22<00:04,  4.49it/s]\u001b[A\n","Epoch 3:  99% 830/839 [08:42<00:05,  1.59it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.189, val_loss_epoch=0.0279, train_loss_epoch=0.0412]\n","Validating:  92% 110/119 [00:24<00:02,  4.49it/s]\u001b[A\n","Validating:  97% 115/119 [00:25<00:00,  4.49it/s]\u001b[A\n","Epoch 3: 100% 839/839 [08:45<00:00,  1.60it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0412]\n","Epoch 3: 100% 839/839 [08:45<00:00,  1.60it/s, loss=0.0229, v_num=0, train_loss_step=0.011, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]tcmalloc: large alloc 3512008704 bytes == 0x7f0904b22000 @  0x7f0e33af6615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f0e16653441 0x7f0df03acf45 0x7f0df03a7491 0x7f0df03ae599 0x7f0e166539cb 0x7f0e162f9a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 4:  86% 720/839 [08:17<01:22,  1.45it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315] \n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:  87% 730/839 [08:19<01:14,  1.46it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:   8% 10/119 [00:02<00:25,  4.35it/s]\u001b[A\n","Epoch 4:  88% 740/839 [08:21<01:07,  1.48it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  17% 20/119 [00:04<00:22,  4.44it/s]\u001b[A\n","Epoch 4:  89% 750/839 [08:23<00:59,  1.49it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  25% 30/119 [00:06<00:19,  4.48it/s]\u001b[A\n","Epoch 4:  91% 760/839 [08:25<00:52,  1.50it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  34% 40/119 [00:09<00:17,  4.48it/s]\u001b[A\n","Epoch 4:  92% 770/839 [08:28<00:45,  1.52it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  42% 50/119 [00:11<00:15,  4.48it/s]\u001b[A\n","Epoch 4:  93% 780/839 [08:30<00:38,  1.53it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  50% 60/119 [00:13<00:13,  4.49it/s]\u001b[A\n","Epoch 4:  94% 790/839 [08:32<00:31,  1.54it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  59% 70/119 [00:15<00:10,  4.49it/s]\u001b[A\n","Epoch 4:  95% 800/839 [08:34<00:25,  1.55it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  67% 80/119 [00:17<00:08,  4.48it/s]\u001b[A\n","Epoch 4:  97% 810/839 [08:37<00:18,  1.57it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  76% 90/119 [00:20<00:06,  4.49it/s]\u001b[A\n","Epoch 4:  98% 820/839 [08:39<00:12,  1.58it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  84% 100/119 [00:22<00:04,  4.49it/s]\u001b[A\n","Epoch 4:  99% 830/839 [08:41<00:05,  1.59it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.210, val_loss_epoch=0.0265, train_loss_epoch=0.0315]\n","Validating:  92% 110/119 [00:24<00:02,  4.49it/s]\u001b[A\n","Validating:  97% 115/119 [00:25<00:00,  4.49it/s]\u001b[A\n","Epoch 4: 100% 839/839 [08:44<00:00,  1.60it/s, loss=0.0234, v_num=0, train_loss_step=0.016, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0315]\n","Epoch 5:  86% 720/839 [08:22<01:23,  1.43it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 5:  87% 730/839 [08:23<01:15,  1.45it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:   8% 10/119 [00:02<00:25,  4.32it/s]\u001b[A\n","Epoch 5:  88% 740/839 [08:26<01:07,  1.46it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  17% 20/119 [00:04<00:22,  4.43it/s]\u001b[A\n","Epoch 5:  89% 750/839 [08:28<01:00,  1.48it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  25% 30/119 [00:06<00:20,  4.44it/s]\u001b[A\n","Epoch 5:  91% 760/839 [08:30<00:53,  1.49it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  34% 40/119 [00:09<00:17,  4.47it/s]\u001b[A\n","Epoch 5:  92% 770/839 [08:32<00:45,  1.50it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  42% 50/119 [00:11<00:15,  4.48it/s]\u001b[A\n","Epoch 5:  93% 780/839 [08:35<00:38,  1.51it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  50% 60/119 [00:13<00:13,  4.48it/s]\u001b[A\n","Epoch 5:  94% 790/839 [08:37<00:32,  1.53it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  59% 70/119 [00:15<00:10,  4.49it/s]\u001b[A\n","Epoch 5:  95% 800/839 [08:39<00:25,  1.54it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  67% 80/119 [00:17<00:08,  4.48it/s]\u001b[A\n","Epoch 5:  97% 810/839 [08:41<00:18,  1.55it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  76% 90/119 [00:20<00:06,  4.47it/s]\u001b[A\n","Epoch 5:  98% 820/839 [08:43<00:12,  1.57it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  84% 100/119 [00:22<00:04,  4.47it/s]\u001b[A\n","Epoch 5:  99% 830/839 [08:46<00:05,  1.58it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.183, val_loss_epoch=0.0234, train_loss_epoch=0.0253]\n","Validating:  92% 110/119 [00:24<00:02,  4.49it/s]\u001b[A\n","Validating:  97% 115/119 [00:25<00:00,  4.49it/s]\u001b[A\n","Epoch 5: 100% 839/839 [08:49<00:00,  1.58it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.221, val_loss_epoch=0.0258, train_loss_epoch=0.0253]\n","Epoch 5: 100% 839/839 [09:18<00:00,  1.50it/s, loss=0.0159, v_num=0, train_loss_step=0.00255, val_loss_step=0.221, val_loss_epoch=0.0258, train_loss_epoch=0.0219]\n"]}]},{"cell_type":"markdown","source":["#### Validate model"],"metadata":{"id":"Z8ERw71vu0VD"}},{"cell_type":"code","source":["!python T5/evaluate.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lm3P81_uu0yO","executionInfo":{"status":"ok","timestamp":1670358368193,"user_tz":-210,"elapsed":163679,"user":{"displayName":"temp tempy","userId":"06017972767897729165"}},"outputId":"40fe1fe9-408b-4c49-babd-cdd78bc34f2c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Global seed set to 42\n","load test data..\n","load model..\n","model path: T5/model/intent_and_slot_simplet5-epoch-5-train-loss-0.0219-val-loss-0.0268\n","evaluate test data..\n","1000it [11:04,  1.51it/s]\n","result data is saved in 'T5/result/T5_result.txt'\n","\n","{'intent_detection': True, 'slot_filling': True}\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","slot scores: [precision:69.44, recall:75.65, F1:72.41]\n","intent accuracy: 0.955\n"]}]},{"cell_type":"markdown","source":["### Just slot filling"],"metadata":{"id":"DnDZM6ldvZNE"}},{"cell_type":"code","source":["!python T5/preprocess.py --intent_detection False --slot_filling True"],"metadata":{"id":"khe7rHsXv6ll","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670342051165,"user_tz":-210,"elapsed":1429,"user":{"displayName":"temp2 tempy","userId":"13958197262983671770"}},"outputId":"d811bc3e-ebe5-4342-c1f4-da80b745f22b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["reading train and val data..\n","reading test data..\n","number of data after remove redundant texts:\n","\t train data: 23016\n","\t val data: 3789\n","\t test data: 7427\n","save prepared data..\n","data is saved in T5/data/\n"]}]},{"cell_type":"code","source":["!python T5/train.py"],"metadata":{"id":"LZKs6zEFwBBt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670347921893,"user_tz":-210,"elapsed":1738995,"user":{"displayName":"temp2 tempy","userId":"13958197262983671770"}},"outputId":"ae11a6fd-b8d7-4c5b-96fb-99e68aea2fc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Global seed set to 42\n","load train and val data..\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Missing logger folder: /content/drive/.shortcut-targets-by-id/1pBBBcAQFBahPZn8EeVxX0HyFNnQB0OZk/NLU/HW2/lightning_logs\n","\n","  | Name  | Type                       | Params\n","-----------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 222 M \n","-----------------------------------------------------\n","222 M     Trainable params\n","0         Non-trainable params\n","222 M     Total params\n","891.614   Total estimated model params size (MB)\n","Global seed set to 42\n","Epoch 0:  86% 720/839 [08:30<01:24,  1.41it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  87% 730/839 [08:31<01:16,  1.43it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:   8% 10/119 [00:02<00:25,  4.26it/s]\u001b[A\n","Epoch 0:  88% 740/839 [08:33<01:08,  1.44it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  17% 20/119 [00:04<00:22,  4.36it/s]\u001b[A\n","Epoch 0:  89% 750/839 [08:36<01:01,  1.45it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  25% 30/119 [00:06<00:20,  4.41it/s]\u001b[A\n","Epoch 0:  91% 760/839 [08:38<00:53,  1.47it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  34% 40/119 [00:09<00:17,  4.42it/s]\u001b[A\n","Epoch 0:  92% 770/839 [08:40<00:46,  1.48it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  42% 50/119 [00:11<00:15,  4.42it/s]\u001b[A\n","Epoch 0:  93% 780/839 [08:43<00:39,  1.49it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  50% 60/119 [00:13<00:13,  4.42it/s]\u001b[A\n","Epoch 0:  94% 790/839 [08:45<00:32,  1.50it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  59% 70/119 [00:15<00:11,  4.42it/s]\u001b[A\n","Epoch 0:  95% 800/839 [08:47<00:25,  1.52it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  67% 80/119 [00:18<00:08,  4.45it/s]\u001b[A\n","Epoch 0:  97% 810/839 [08:49<00:18,  1.53it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  76% 90/119 [00:20<00:06,  4.45it/s]\u001b[A\n","Epoch 0:  98% 820/839 [08:52<00:12,  1.54it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  84% 100/119 [00:22<00:04,  4.45it/s]\u001b[A\n","Epoch 0:  99% 830/839 [08:54<00:05,  1.55it/s, loss=0.0897, v_num=0, train_loss_step=0.0664]\n","Validating:  92% 110/119 [00:24<00:02,  4.43it/s]\u001b[A\n","Validating:  97% 115/119 [00:26<00:00,  4.44it/s]\u001b[A\n","Epoch 0: 100% 839/839 [08:57<00:00,  1.56it/s, loss=0.0897, v_num=0, train_loss_step=0.0664, val_loss_step=0.275, val_loss_epoch=0.0615]\n","Epoch 0: 100% 839/839 [08:57<00:00,  1.56it/s, loss=0.0897, v_num=0, train_loss_step=0.0664, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]tcmalloc: large alloc 1150812160 bytes == 0x124582000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 1438515200 bytes == 0xbee48000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 1798144000 bytes == 0x124582000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 2247680000 bytes == 0x7f13ec072000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 2809602048 bytes == 0x124582000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 3512008704 bytes == 0x7f131ab22000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 1:  86% 720/839 [08:20<01:22,  1.44it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:  87% 730/839 [08:22<01:14,  1.45it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:   8% 10/119 [00:02<00:26,  4.18it/s]\u001b[A\n","Epoch 1:  88% 740/839 [08:24<01:07,  1.47it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  17% 20/119 [00:04<00:22,  4.33it/s]\u001b[A\n","Epoch 1:  89% 750/839 [08:26<01:00,  1.48it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  25% 30/119 [00:06<00:20,  4.39it/s]\u001b[A\n","Epoch 1:  91% 760/839 [08:28<00:52,  1.49it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  34% 40/119 [00:09<00:17,  4.41it/s]\u001b[A\n","Epoch 1:  92% 770/839 [08:31<00:45,  1.51it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  42% 50/119 [00:11<00:15,  4.42it/s]\u001b[A\n","Epoch 1:  93% 780/839 [08:33<00:38,  1.52it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  50% 60/119 [00:13<00:13,  4.46it/s]\u001b[A\n","Epoch 1:  94% 790/839 [08:35<00:31,  1.53it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  59% 70/119 [00:15<00:10,  4.46it/s]\u001b[A\n","Epoch 1:  95% 800/839 [08:37<00:25,  1.54it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  67% 80/119 [00:18<00:08,  4.46it/s]\u001b[A\n","Epoch 1:  97% 810/839 [08:40<00:18,  1.56it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  76% 90/119 [00:20<00:06,  4.43it/s]\u001b[A\n","Epoch 1:  98% 820/839 [08:42<00:12,  1.57it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  84% 100/119 [00:22<00:04,  4.43it/s]\u001b[A\n","Epoch 1:  99% 830/839 [08:44<00:05,  1.58it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.275, val_loss_epoch=0.0615, train_loss_epoch=0.243]\n","Validating:  92% 110/119 [00:24<00:02,  4.46it/s]\u001b[A\n","Validating:  97% 115/119 [00:26<00:00,  4.46it/s]\u001b[A\n","Epoch 1: 100% 839/839 [08:48<00:00,  1.59it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.243]\n","Epoch 1: 100% 839/839 [08:48<00:00,  1.59it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]tcmalloc: large alloc 2247680000 bytes == 0x7f131ab22000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 1: 100% 839/839 [09:02<00:00,  1.55it/s, loss=0.0502, v_num=0, train_loss_step=0.0277, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]tcmalloc: large alloc 2809602048 bytes == 0x124582000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","tcmalloc: large alloc 3512008704 bytes == 0x7f131ab22000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n","Epoch 2:  86% 720/839 [08:21<01:22,  1.43it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/119 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:  87% 730/839 [08:23<01:15,  1.45it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:   8% 10/119 [00:02<00:25,  4.24it/s]\u001b[A\n","Epoch 2:  88% 740/839 [08:25<01:07,  1.46it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  17% 20/119 [00:04<00:22,  4.36it/s]\u001b[A\n","Epoch 2:  89% 750/839 [08:27<01:00,  1.48it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  25% 30/119 [00:06<00:20,  4.41it/s]\u001b[A\n","Epoch 2:  91% 760/839 [08:30<00:53,  1.49it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  34% 40/119 [00:09<00:17,  4.44it/s]\u001b[A\n","Epoch 2:  92% 770/839 [08:32<00:45,  1.50it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  42% 50/119 [00:11<00:15,  4.46it/s]\u001b[A\n","Epoch 2:  93% 780/839 [08:34<00:38,  1.52it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  50% 60/119 [00:13<00:13,  4.45it/s]\u001b[A\n","Epoch 2:  94% 790/839 [08:36<00:32,  1.53it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  59% 70/119 [00:15<00:10,  4.47it/s]\u001b[A\n","Epoch 2:  95% 800/839 [08:38<00:25,  1.54it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  67% 80/119 [00:18<00:08,  4.47it/s]\u001b[A\n","Epoch 2:  97% 810/839 [08:41<00:18,  1.55it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  76% 90/119 [00:20<00:06,  4.48it/s]\u001b[A\n","Epoch 2:  98% 820/839 [08:43<00:12,  1.57it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  84% 100/119 [00:22<00:04,  4.48it/s]\u001b[A\n","Epoch 2:  99% 830/839 [08:45<00:05,  1.58it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.232, val_loss_epoch=0.0399, train_loss_epoch=0.0641]\n","Validating:  92% 110/119 [00:24<00:02,  4.48it/s]\u001b[A\n","Validating:  97% 115/119 [00:25<00:00,  4.47it/s]\u001b[A\n","Epoch 2: 100% 839/839 [08:48<00:00,  1.59it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.237, val_loss_epoch=0.0316, train_loss_epoch=0.0641]\n","Epoch 2: 100% 839/839 [09:03<00:00,  1.54it/s, loss=0.0298, v_num=0, train_loss_step=0.0486, val_loss_step=0.237, val_loss_epoch=0.0316, train_loss_epoch=0.0399]tcmalloc: large alloc 3512008704 bytes == 0x7f131ab22000 @  0x7f184d55a615 0x5d631c 0x51e4f1 0x51e67b 0x5a9f95 0x5d78b6 0x7f18300b7441 0x7f1809e10f45 0x7f1809e0b491 0x7f1809e12599 0x7f18300b79cb 0x7f182fd5da3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1\n"]}]},{"cell_type":"code","source":["!python T5/evaluate.py\n","\n","# slot scores: [precision:55.14, recall:65.87, F1:60.03]\n","# slot scores: [precision:70.27, recall:75.8, F1:72.93]\n","# slot scores: [precision:71.93, recall:76.52, F1:74.15]"],"metadata":{"id":"9lcE0D02wDik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Just intent detection"],"metadata":{"id":"TxzduM23vmWn"}},{"cell_type":"code","source":["!python T5/preprocess.py --intent_detection True --slot_filling False"],"metadata":{"id":"ofkDSiCLwFG4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python T5/train.py"],"metadata":{"id":"qjHaZ1IywFG4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python T5/evaluate.py"],"metadata":{"id":"ZoZk4bvvwFG5"},"execution_count":null,"outputs":[]}]}